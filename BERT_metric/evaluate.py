### NAME:           evaluate.py
### PURPOSE:        Evaluation of the BERT metric.
### AUTHOR:         Mortiz Altemeyer, Philipp Hege
### LAST CHANGE:    24.08.2022

# Import packages
import os
import numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.stats import pearsonr
from datetime import datetime
from sklearn.metrics import mean_squared_error
from tools import StandardDeviation, LoadAndPreprocessAndNormalizeData # local .py file


def evaluate_metric(TRAINER,
                    TRAIN_INFO,
                    DATA_PATH = 'data/data_2017_test.csv',
                    EVAL_SIZE = 100,
                    ADAPTER = False,
                    SCATTER_PATH = None):
    '''
    pass
    
    :param TRAINER: Trainer object. Fully trained trainer from train.py.
    :param TRAIN_INFO: Tuple. Info how the model was trained yielding the trainer. Tuple like: (Number epochs, number data points, test size).
    :param DATA_PATH: String. Default: 'data/data_2017_test.csv'. Directory, name and extension of the evaluation data. 
    :param EVAL_SIZE: Integer > 0. Default: 100. Number of data points used for evaluation.
    :param ADAPTER: Bool. Default: False. States if the trainer was trained using adapters.
    :param SCATTER_PATH: String. Default: None. Directory of the scatter plot. When default, the plot is not saved.
    
    :return runtime: Float. Runtime of the evaluation.
    :return pearsonR: Float. PearsonR correlation coefficient (PCC) of the evaluation.
    :return predictions: np.array. Contains the predictions generated by the model during the evaluation.
    :return std: Float. Standard deviation of the evaluation.
    :return mse: Float. Mean Squared Error (MSE) of the evaluation.
    '''
    # extract model name (with adapter extension if ADAPTER=True)
    if ADAPTER:
        adapter = '_adapter'
    else:
        adapter = ''
    model_name = TRAINER.model.config._name_or_path + adapter
    # get corresponding tokenizer and model
    tokenizer = AutoTokenizer.from_pretrained('./model_checkpoints/{0}__{1}__{2}__{3}'.format(model_name, TRAIN_INFO[0], TRAIN_INFO[1], TRAIN_INFO[2]))
    model = AutoModelForSequenceClassification.from_pretrained('./model_checkpoints/{0}__{1}__{2}__{3}'.format(model_name, TRAIN_INFO[0], TRAIN_INFO[1], TRAIN_INFO[2]))    
    
    # load adapters and activate them onto the model if we have some
    if ADAPTER:
        adapter_name = model.load_adapter('./model_checkpoints/{0}__{1}__{2}__{3}/Regression'.format(model_name, TRAIN_INFO[0], TRAIN_INFO[1], TRAIN_INFO[2]))
        model.set_active_adapters(adapter_name)
    
    # get evaluation data loaded, normalized and preprocessed
    evaluation_data = LoadAndPreprocessAndNormalizeData(DATA_PATH, tokenizer, EVAL_SIZE)
    
    t0 = datetime.now() # measure time: start
    
    # make prediction
    predictions = TRAINER.predict(evaluation_data)
    
    t1 = datetime.now() # measure time: end
    runtime = (t1 - t0).total_seconds() # get runtime in seconds
    
    # extract predictions
    predictions = np.array([i[0] for i in predictions[0]])
    
    # compare prediction to actual labels: compute MSE, pearsonR (PCC) and standard deviation
    mse = mean_squared_error(evaluation_data['labels'], predictions)
    correlation = pearsonr(predictions, evaluation_data['labels']) # correlation.statistic only gives correlation score (without p-value)
    pearsonR = correlation.statistic
    std = StandardDeviation(predictions, np.array(evaluation_data['labels']))
    
    # if a path for the scatter plot is given, it should be saved
    if SCATTER_PATH:
        plt.rcParams.update({'font.size': 20}) # overall (axes, labels) font size to 20
        plt.figure(figsize=(10,10))
        plt.scatter(evaluation_data['labels'], predictions) # make plot
        plt.xlabel('Actual Score') # labeling of x-axis
        plt.ylabel('Predicted Score') # labeling of y-axis
        plt.xlim(-0.05, 1.05) # bounds of x-axis
        plt.ylim(-0.05, 1.05) # bounds of y-axis
        plt.grid(True) # make grid
        
        # create directory of it does not exist
        isExist = os.path.exists(SCATTER_PATH)
        if not isExist:
            # Create a new directory because it does not exist
            os.makedirs(SCATTER_PATH)
            print(f'New directory created: {SCATTER_PATH}')
        
        # write the figure as a pdf with 100 dpi in the specified directory
        filename = f'correlation{adapter}.pdf'
        try:
            plt.savefig(os.path.join(SCATTER_PATH, filename), dpi=100)
            print('File written successfully: ', os.path.join(SCATTER_PATH, filename))
        except Exception as E:
            print(E)
             
    return runtime, pearsonR, predictions, std, mse